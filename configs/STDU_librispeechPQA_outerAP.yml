train:
  way: 5
  shot: 5
  num_session: 9
  num_base: 60
  num_novel: 40
  num_all: 100
  start_session: 0
  test_times: 1
  seq_sample: false
  tmp_train: false
  model_dir:
    sis_model_dir: null # for sis
    tmp_model_dir: null # SIS temp model paht
    s0_model_dir: null # session 0's final model path
    sf_model_dir: null # final session's model path
  seed: 0
  epochs:
    epochs_std: 1
    epochs_sis_base: 1
    epochs_cec_base: 1
    epochs_new: 1
  lr:
    lr_std: !!float 0.1
    lr_base: !!float 0.1
    lr_new: !!float 0.1
    lr_cec_base: 0.0002
    lr_sis_base: 0.0002
    lrg: !!float 0.0002  #lr for graph attention
  scheduler: 
    schedule: Step # ['Step', 'Milestone']
    milestones: [40, 80]
    step: 40
    gamma: !!float 0.5
  optimizer:
    decay: !!float 0.0005
    momentum: !!float 0.9
  network:
    temperature: 16
    base_mode: ft_cos  # ['ft_dot', 'ft_cos']
    new_mode: ft_cos  # ['ft_dot', 'ft_cos', 'avg_cos'] ft_dot means using linear classifier, ft_cos means using cosine classifier, avg_cos means using average data embedding and cosine classifier
  strategy:
    not_data_init: false
    set_no_val: false
    seq_sample: false
  episode:
    train_episode: 50
    episode_way: 5
    episode_shot: 5
    episode_query: 15
    low_way: 5
    low_shot: 5
  dataloader:
    num_workers: 8
    train_batch_size: 128
    test_batch_size: 100
  STDU:
    num_tmpb: 35
    num_tmpi: 25
    num_tmps: 14
    num_incre: 5
    pqa: true
    ap:
      use_ap: true
      ap_type: outer
  extractor:
    sample_rate: 16000
    window_size: 400
    hop_size: 160
    mel_bins: 80
    fmin: 0
    fmax: 8000
    window: hann



